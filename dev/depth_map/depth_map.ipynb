{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f37e311b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: djitellopy in /home/santos/anaconda3/lib/python3.9/site-packages (2.4.0)\n",
      "Requirement already satisfied: numpy in /home/santos/anaconda3/lib/python3.9/site-packages (from djitellopy) (1.21.5)\n",
      "Requirement already satisfied: opencv-python in /home/santos/anaconda3/lib/python3.9/site-packages (from djitellopy) (4.6.0.66)\n",
      "Requirement already satisfied: timm in /home/santos/anaconda3/lib/python3.9/site-packages (0.6.7)\n",
      "Requirement already satisfied: torchvision in /home/santos/anaconda3/lib/python3.9/site-packages (from timm) (0.13.1)\n",
      "Requirement already satisfied: torch>=1.4 in /home/santos/anaconda3/lib/python3.9/site-packages (from timm) (1.12.1)\n",
      "Requirement already satisfied: typing-extensions in /home/santos/anaconda3/lib/python3.9/site-packages (from torch>=1.4->timm) (4.1.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/santos/anaconda3/lib/python3.9/site-packages (from torchvision->timm) (9.0.1)\n",
      "Requirement already satisfied: numpy in /home/santos/anaconda3/lib/python3.9/site-packages (from torchvision->timm) (1.21.5)\n",
      "Requirement already satisfied: requests in /home/santos/anaconda3/lib/python3.9/site-packages (from torchvision->timm) (2.27.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/santos/anaconda3/lib/python3.9/site-packages (from requests->torchvision->timm) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/santos/anaconda3/lib/python3.9/site-packages (from requests->torchvision->timm) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/santos/anaconda3/lib/python3.9/site-packages (from requests->torchvision->timm) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/santos/anaconda3/lib/python3.9/site-packages (from requests->torchvision->timm) (2.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install djitellopy\n",
    "!pip install timm\n",
    "from djitellopy import tello\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import urllib.request\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "765aeb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/santos/.cache/torch/hub/intel-isl_MiDaS_master\n",
      "Using cache found in /home/santos/.cache/torch/hub/intel-isl_MiDaS_master\n"
     ]
    }
   ],
   "source": [
    "model_type = \"DPT_Large\"\n",
    "\n",
    "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type)\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "midas.to(device)\n",
    "midas.eval()\n",
    "\n",
    "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
    "\n",
    "if model_type == \"DPT_Large\" or model_type == \"DPT_Hybrid\":\n",
    "    transform = midas_transforms.dpt_transform\n",
    "else:\n",
    "    transform = midas_transforms.small_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb83fd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower = np.array([0, 0, 11])\n",
    "upper = np.array([0, 0, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81c7cec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] tello.py - 122 - Tello instance was initialized. Host: '192.168.10.1'. Port: '8889'.\n",
      "[INFO] tello.py - 437 - Send command: 'command'\n",
      "[INFO] tello.py - 461 - Response command: 'ok'\n",
      "[INFO] tello.py - 437 - Send command: 'streamon'\n",
      "[INFO] tello.py - 461 - Response streamon: 'ok'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n"
     ]
    }
   ],
   "source": [
    "drone = tello.Tello()\n",
    "drone.connect()\n",
    "print(drone.get_battery())\n",
    "drone.streamon()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2f76254",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] decode_slice_header error\n",
      "[h264 @ 0x5611b39af4c0] no frame!\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] decode_slice_header error\n",
      "[h264 @ 0x5611b39af4c0] no frame!\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] decode_slice_header error\n",
      "[h264 @ 0x5611b39af4c0] no frame!\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] decode_slice_header error\n",
      "[h264 @ 0x5611b39af4c0] no frame!\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] decode_slice_header error\n",
      "[h264 @ 0x5611b39af4c0] no frame!\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] decode_slice_header error\n",
      "[h264 @ 0x5611b39af4c0] no frame!\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] decode_slice_header error\n",
      "[h264 @ 0x5611b39af4c0] no frame!\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] decode_slice_header error\n",
      "[h264 @ 0x5611b39af4c0] no frame!\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] decode_slice_header error\n",
      "[h264 @ 0x5611b39af4c0] no frame!\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] decode_slice_header error\n",
      "[h264 @ 0x5611b39af4c0] no frame!\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] decode_slice_header error\n",
      "[h264 @ 0x5611b39af4c0] no frame!\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] decode_slice_header error\n",
      "[h264 @ 0x5611b39af4c0] no frame!\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] decode_slice_header error\n",
      "[h264 @ 0x5611b39af4c0] no frame!\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] decode_slice_header error\n",
      "[h264 @ 0x5611b39af4c0] no frame!\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] decode_slice_header error\n",
      "[h264 @ 0x5611b39af4c0] no frame!\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] decode_slice_header error\n",
      "[h264 @ 0x5611b39af4c0] no frame!\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] decode_slice_header error\n",
      "[h264 @ 0x5611b39af4c0] no frame!\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] decode_slice_header error\n",
      "[h264 @ 0x5611b39af4c0] no frame!\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] decode_slice_header error\n",
      "[h264 @ 0x5611b39af4c0] no frame!\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] decode_slice_header error\n",
      "[h264 @ 0x5611b39af4c0] no frame!\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] decode_slice_header error\n",
      "[h264 @ 0x5611b39af4c0] no frame!\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] decode_slice_header error\n",
      "[h264 @ 0x5611b39af4c0] no frame!\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] decode_slice_header error\n",
      "[h264 @ 0x5611b39af4c0] no frame!\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] decode_slice_header error\n",
      "[h264 @ 0x5611b39af4c0] no frame!\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] decode_slice_header error\n",
      "[h264 @ 0x5611b39af4c0] no frame!\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] decode_slice_header error\n",
      "[h264 @ 0x5611b39af4c0] no frame!\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] decode_slice_header error\n",
      "[h264 @ 0x5611b39af4c0] no frame!\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] decode_slice_header error\n",
      "[h264 @ 0x5611b39af4c0] no frame!\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] non-existing PPS 0 referenced\n",
      "[h264 @ 0x5611b39af4c0] decode_slice_header error\n",
      "[h264 @ 0x5611b39af4c0] no frame!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m input_batch \u001b[38;5;241m=\u001b[39m transform(img)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 9\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmidas\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39minterpolate(\n\u001b[1;32m     12\u001b[0m         prediction\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     13\u001b[0m         size\u001b[38;5;241m=\u001b[39mimg\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m],\n\u001b[1;32m     14\u001b[0m         mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbicubic\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     15\u001b[0m         align_corners\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     16\u001b[0m     )\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m     18\u001b[0m depth_map \u001b[38;5;241m=\u001b[39m prediction\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.cache/torch/hub/intel-isl_MiDaS_master/midas/dpt_depth.py:108\u001b[0m, in \u001b[0;36mDPTDepthModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.cache/torch/hub/intel-isl_MiDaS_master/midas/dpt_depth.py:71\u001b[0m, in \u001b[0;36mDPT.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannels_last \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m     x\u001b[38;5;241m.\u001b[39mcontiguous(memory_format\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mchannels_last)\n\u001b[0;32m---> 71\u001b[0m layer_1, layer_2, layer_3, layer_4 \u001b[38;5;241m=\u001b[39m \u001b[43mforward_vit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretrained\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m layer_1_rn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscratch\u001b[38;5;241m.\u001b[39mlayer1_rn(layer_1)\n\u001b[1;32m     74\u001b[0m layer_2_rn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscratch\u001b[38;5;241m.\u001b[39mlayer2_rn(layer_2)\n",
      "File \u001b[0;32m~/.cache/torch/hub/intel-isl_MiDaS_master/midas/vit.py:59\u001b[0m, in \u001b[0;36mforward_vit\u001b[0;34m(pretrained, x)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_vit\u001b[39m(pretrained, x):\n\u001b[1;32m     57\u001b[0m     b, c, h, w \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m---> 59\u001b[0m     glob \u001b[38;5;241m=\u001b[39m \u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_flex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     layer_1 \u001b[38;5;241m=\u001b[39m pretrained\u001b[38;5;241m.\u001b[39mactivations[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     62\u001b[0m     layer_2 \u001b[38;5;241m=\u001b[39m pretrained\u001b[38;5;241m.\u001b[39mactivations[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.cache/torch/hub/intel-isl_MiDaS_master/midas/vit.py:149\u001b[0m, in \u001b[0;36mforward_flex\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    146\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_drop(x)\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m--> 149\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(x)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/timm/models/vision_transformer.py:242\u001b[0m, in \u001b[0;36mBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 242\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mls1(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m    243\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mls2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x))))\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/timm/models/vision_transformer.py:204\u001b[0m, in \u001b[0;36mAttention.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    201\u001b[0m qkv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqkv(x)\u001b[38;5;241m.\u001b[39mreshape(B, N, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, C \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m    202\u001b[0m q, k, v \u001b[38;5;241m=\u001b[39m qkv\u001b[38;5;241m.\u001b[39munbind(\u001b[38;5;241m0\u001b[39m)   \u001b[38;5;66;03m# make torchscript happy (cannot use tensor as tuple)\u001b[39;00m\n\u001b[0;32m--> 204\u001b[0m attn \u001b[38;5;241m=\u001b[39m (\u001b[43mq\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale\n\u001b[1;32m    205\u001b[0m attn \u001b[38;5;241m=\u001b[39m attn\u001b[38;5;241m.\u001b[39msoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    206\u001b[0m attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_drop(attn)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:   \n",
    "    img = drone.get_frame_read().frame\n",
    "    num = random.randint(1,10000)\n",
    "    cv2.imwrite(f\"img/{num}.jpg\", img)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    input_batch = transform(img).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prediction = midas(input_batch)\n",
    "\n",
    "        prediction = torch.nn.functional.interpolate(\n",
    "            prediction.unsqueeze(1),\n",
    "            size=img.shape[:2],\n",
    "            mode=\"bicubic\",\n",
    "            align_corners=False,\n",
    "        ).squeeze()\n",
    "\n",
    "    depth_map = prediction.cpu().numpy()\n",
    "\n",
    "    depth_map = cv2.normalize(depth_map, None, 0, 1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_64F)\n",
    "    depth_map = (depth_map*255).astype(np.uint8)\n",
    "    depth_map = cv2.applyColorMap(depth_map, cv2.COLORMAP_MAGMA)\n",
    "    \n",
    "    M = depth_map.shape[0]//4\n",
    "    N = depth_map.shape[1]//4\n",
    "    tiles = [depth_map[x:x+M,y:y+N] for x in range(0,depth_map.shape[0],M) for y in range(0,depth_map.shape[1],N)]\n",
    "    \n",
    "    d1 = cv2.vconcat([tiles[0], tiles[1], tiles[2], tiles[3]])\n",
    "    d2 = cv2.vconcat([tiles[4], tiles[5], tiles[6], tiles[7]])\n",
    "    depth_map = cv2.hconcat([d1, d2])\n",
    "    \n",
    "    cv2.imwrite(f\"img/depth_{num}.jpg\", depth_map)\n",
    "    output = cv2.imread(f\"img/depth_{num}.jpg\")\n",
    "    \n",
    "    output = cv2.cvtColor(output, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.inRange(output, lower, upper)\n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if len(contours) != 0:\n",
    "        for contour in contours:\n",
    "            if cv2.contourArea(contour) > 500:\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                cv2.rectangle(mask, (x, y), (x + w, y + h), (0, 0, 255), 3)\n",
    "                \n",
    "    #cv2.imwrite(f\"img/{num}(1).jpg\", mask)\n",
    "    \n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4847c6f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"3047\"\n",
    "output = cv2.imread(f\"img/{path}.jpg\")\n",
    "    \n",
    "output = cv2.cvtColor(output, cv2.COLOR_RGB2HSV)\n",
    "mask = cv2.inRange(output, lower, upper)\n",
    "    \n",
    "cv2.imwrite(f\"img/{path}({random.randint(1, 100)}).jpg\", mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5aa4ebdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@2040.709] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('depth_3937.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg/test.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m, depth_map)\n\u001b[1;32m     12\u001b[0m i \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdepth_3937.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcatenate\u001b[39m(img):\n\u001b[0;32m----> 2\u001b[0m     M \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m4\u001b[39m\n\u001b[1;32m      3\u001b[0m     N \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m4\u001b[39m\n\u001b[1;32m      4\u001b[0m     tiles \u001b[38;5;241m=\u001b[39m [img[x:x\u001b[38;5;241m+\u001b[39mM,y:y\u001b[38;5;241m+\u001b[39mN] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],M) \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],N)]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "def concatenate(img):\n",
    "    M = img.shape[0]//4\n",
    "    N = img.shape[1]//4\n",
    "    tiles = [img[x:x+M,y:y+N] for x in range(0,img.shape[0],M) for y in range(0,img.shape[1],N)]\n",
    "    \n",
    "    d1 = cv2.vconcat([tiles[0], tiles[1], tiles[2], tiles[3]])\n",
    "    d2 = cv2.vconcat([tiles[4], tiles[5], tiles[6], tiles[7]])\n",
    "    depth_map = cv2.hconcat([d1, d2])\n",
    "    \n",
    "    cv2.imwrite(\"img/test.jpg\", depth_map)\n",
    "    \n",
    "i = cv2.imread(f\"depth_3937.jpg\")\n",
    "concatenate(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527a2396",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
